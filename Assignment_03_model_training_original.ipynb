{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group information**\n",
    "\n",
    "| Family name | First name | Email address |\n",
    "| ----------- | ---------- | ------------- |\n",
    "|             |            |               |\n",
    "|             |            |               |\n",
    "|             |            |               |\n",
    "\n",
    "**Design Document**\n",
    "Add your Design Document based on Lecture 1 below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMmWP-Z9OfcN"
   },
   "source": [
    "\n",
    "# Assignment_03_model_training_solution\n",
    "\n",
    "Make sure to use a GPU and have access to internet connection in the Kaggle notebook:\n",
    "\n",
    "1.  On the arrow on the bottom right, select \"Notebook Options\" and then \"Accelerator\" to choose the GPU P100, and select \"Variables & Files\" under Persistence. **Note that Kaggle allows 30h per week per user of accelerated computing. Plan your work accordingly. It takes time to load the data and you may experience unavailability of GPUs or Session Errors.**\n",
    "1. Make sure your Kaggle account is phone verified by clicking \"Get phone verified\" in the left sidebar under \"Notebook options\" and following the steps (this step is required to switch on the internet connection needed to install packages). \n",
    "1. After phone verification, the full settings menu should be visible. Toggle the \"Internet\" switch.\n",
    "\n",
    "More visualizations of the process to connect the notebook to the internet are provided [here](https://stackoverflow.com/questions/68142524/cannot-access-internet-on-kaggle-notebook)\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. Downloading the tiles of the ecti2021 here: [ecti2021.zip](https://www.dropbox.com/scl/fi/tuvroadxyummourvx6cmz/ecti2021.zip?rlkey=wsc19sue84ytkphheptq28ica&st=9p8npaly&dl=0)\n",
    "1. Go to the \"Side Bar\", Click on \"Input\"\n",
    "1. Upload as `ecti2021` the file: `ecti2021.zip`  which contains the following four files: `train.zip`, `val_without_ref_labels.zip` , and the `water_tiles.csv` and `background_tiles.csv` from the `data_preparation.ipynb` notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kw4dck9KZ51j"
   },
   "source": [
    "# Step 0: Enviroment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T15:46:18.500226Z",
     "iopub.status.busy": "2025-03-22T15:46:18.499808Z",
     "iopub.status.idle": "2025-03-22T15:46:32.976347Z",
     "shell.execute_reply": "2025-03-22T15:46:32.975278Z",
     "shell.execute_reply.started": "2025-03-22T15:46:18.500194Z"
    },
    "id": "U4gpxAZ9QkzJ",
    "outputId": "04271f1b-cae9-4626-e65a-f58a1518c675",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "!pip install -U git+https://github.com/albu/albumentations --no-cache-di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:46:32.978110Z",
     "iopub.status.busy": "2025-03-22T15:46:32.977746Z",
     "iopub.status.idle": "2025-03-22T15:46:43.717968Z",
     "shell.execute_reply": "2025-03-22T15:46:43.717072Z",
     "shell.execute_reply.started": "2025-03-22T15:46:32.978075Z"
    },
    "id": "mz4KCyB4Pw6Q",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "# Set up plotting options\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from pickle import load\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4TkxVV6PpI-"
   },
   "source": [
    "# Step 1: Load the dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:54:36.600087Z",
     "iopub.status.busy": "2025-03-22T12:54:36.599792Z",
     "iopub.status.idle": "2025-03-22T12:54:36.607213Z",
     "shell.execute_reply": "2025-03-22T12:54:36.606452Z",
     "shell.execute_reply.started": "2025-03-22T12:54:36.600066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set path to where dataset is downloaded\n",
    "dataset_root = '/kaggle/input/ecti2021/ecti2021/ecti2021' #set accordingly based on how you uploaded the data\n",
    "# get number of training/validation regions\n",
    "train_dir = os.path.join(dataset_root, 'train/train')\n",
    "test_dir = os.path.join(dataset_root, 'val_without_ref_labels/val')\n",
    "\n",
    "n_train_regions = len(glob(train_dir+'/*/'))\n",
    "n_test_regions = len(glob(test_dir+'/*/'))\n",
    "\n",
    "# NOTE: make sure number of regions is NOT 0, otherwise it might be that the code is not able to read the data. \n",
    "print('Number of training temporal-regions: {}'.format(n_train_regions))\n",
    "print('Number of test temporal-regions: {}'.format(n_test_regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Lab_01_data_preparation, we identified that the ETCI 2021 Competition on Flood Detection is composed of 33'405 tiles. However, we also identified tiles that have empty VV/VH but have a non-zero label. We already excluded these tiles when saving the `water_tiles.csv` and `background_tiles.csv`. The dataset used in this notebook should contain 27'214 tiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWNe2TxWVrQ1"
   },
   "source": [
    "## Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:54:44.661812Z",
     "iopub.status.busy": "2025-03-22T12:54:44.661442Z",
     "iopub.status.idle": "2025-03-22T12:54:44.670474Z",
     "shell.execute_reply": "2025-03-22T12:54:44.669718Z",
     "shell.execute_reply.started": "2025-03-22T12:54:44.661782Z"
    },
    "id": "lHnXysQzVtr_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize(df_row, figsize=[25, 15]):\n",
    "    # get image paths\n",
    "    vv_image_path = df_row['vv_image_path']\n",
    "    vh_image_path = df_row['vh_image_path']\n",
    "    flood_label_path = df_row['flood_label_path']\n",
    "    water_body_label_path = df_row['water_body_label_path']\n",
    "\n",
    "    # create RGB image from S1 images\n",
    "    rgb_name = get_filename(vv_image_path)\n",
    "    vv_image = cv2.imread(vv_image_path, 0) / 255.0\n",
    "    vh_image = cv2.imread(vh_image_path, 0) / 255.0\n",
    "    rgb_image = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "    # get water body label mask\n",
    "    water_body_label_image = cv2.imread(water_body_label_path, 0) / 255.0\n",
    "\n",
    "    # plot images\n",
    "    plt.figure(figsize=tuple(figsize))\n",
    "    if df_row.isnull().sum() > 0:\n",
    "        # plot RGB S1 image\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(rgb_image)\n",
    "        plt.title(rgb_name)\n",
    "\n",
    "        # plot water body mask\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(water_body_label_image)\n",
    "        plt.title('Water body mask')\n",
    "    else:\n",
    "        flood_label_image = cv2.imread(flood_label_path, 0) / 255.0\n",
    "        # plot RGB S1 image\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(rgb_image)\n",
    "        plt.title(rgb_name)\n",
    "\n",
    "        # plot flood label mask\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(flood_label_image)\n",
    "        plt.title('Flood mask')\n",
    "\n",
    "        # plot water body mask\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(water_body_label_image)\n",
    "        plt.title('Water body mask')\n",
    "\n",
    "def s1_to_rgb(vv_image, vh_image):\n",
    "    eps=1e-06\n",
    "    ratio_image = np.clip(np.nan_to_num(vv_image/(vh_image+eps), 0), 0, 1) # outside [0,1] will be clipped\n",
    "    rgb_image = np.stack((vv_image, vh_image, ratio_image), axis=2) #different from lab01: np.abs(red) / np.abs(green) \n",
    "    return rgb_image\n",
    "\n",
    "def visualize_result(df_row, prediction, figsize=[25, 15]):\n",
    "    vv_image = cv2.imread(df_row['vv_image_path'], 0) / 255.0\n",
    "    vh_image = cv2.imread(df_row['vh_image_path'], 0) / 255.0\n",
    "    rgb_input = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "    plt.figure(figsize=tuple(figsize))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(rgb_input)\n",
    "    plt.title('RGB w/ result')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(prediction)\n",
    "    plt.title('Result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMhA2NnmQ5-G"
   },
   "source": [
    "# Step 2: Create training dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:54:48.650369Z",
     "iopub.status.busy": "2025-03-22T12:54:48.650052Z",
     "iopub.status.idle": "2025-03-22T12:54:48.654886Z",
     "shell.execute_reply": "2025-03-22T12:54:48.653989Z",
     "shell.execute_reply.started": "2025-03-22T12:54:48.650343Z"
    },
    "id": "qNuQSgeaZ51l",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_filename(filepath,split_symbol='/'):\n",
    "    return filepath.split(split_symbol)[-1]\n",
    "\n",
    "def read_csv(csvpath,split_symbol='\\\\'):\n",
    "    path_list = np.loadtxt(csvpath,delimiter=\" \", dtype=str).tolist()\n",
    "    return [get_filename(pth,split_symbol) for pth in path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:55:02.167626Z",
     "iopub.status.busy": "2025-03-22T12:55:02.167286Z",
     "iopub.status.idle": "2025-03-22T12:55:02.599558Z",
     "shell.execute_reply": "2025-03-22T12:55:02.598669Z",
     "shell.execute_reply.started": "2025-03-22T12:55:02.167598Z"
    },
    "id": "WOsizzvDQyli",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "water_image_names = read_csv('/kaggle/input/ecti2021/ecti2021/ecti2021/water_tiles.csv') #from lab01 make sure the path is correct\n",
    "background_image_names = read_csv('/kaggle/input/ecti2021/ecti2021/ecti2021/background_tiles.csv')\n",
    "\n",
    "region_name_dates0 = ['_'.join(n.split('_')[:2]) for n in water_image_names]\n",
    "region_name_dates1 = ['_'.join(n.split('_')[:2]) for n in background_image_names]\n",
    "\n",
    "vv_image_paths, vh_image_paths, flood_label_paths, water_body_label_paths = [], [], [], []\n",
    "\n",
    "\n",
    "water_image_paths,background_image_paths = [],[]\n",
    "\n",
    "for i in range(len(water_image_names)):\n",
    "    vv_image_path = os.path.join(train_dir, region_name_dates0[i], 'tiles', 'vv', water_image_names[i])\n",
    "    vv_image_paths.append(vv_image_path)\n",
    "    water_image_paths.append(vv_image_path)\n",
    "    \n",
    "    # get vh image path\n",
    "    vh_image_name = water_image_names[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(train_dir, region_name_dates0[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths.append(vh_image_path)\n",
    "\n",
    "    # get flood mask path\n",
    "    flood_image_name = water_image_names[i].replace('_vv', '')\n",
    "    flood_label_path = os.path.join(train_dir, region_name_dates0[i], 'tiles', 'flood_label', flood_image_name)\n",
    "    flood_label_paths.append(flood_label_path)\n",
    "\n",
    "    # get water body mask path\n",
    "    water_body_label_name = water_image_names[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(train_dir, region_name_dates0[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths.append(water_body_label_path)\n",
    "    \n",
    "for i in range(len(background_image_names)):\n",
    "    vv_image_path = os.path.join(train_dir, region_name_dates1[i], 'tiles', 'vv', background_image_names[i])\n",
    "    vv_image_paths.append(vv_image_path)\n",
    "    background_image_paths.append(vv_image_path)\n",
    "    \n",
    "    # get vh image path\n",
    "    vh_image_name = background_image_names[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(train_dir, region_name_dates1[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths.append(vh_image_path)\n",
    "\n",
    "    # get flood mask path\n",
    "    flood_image_name = background_image_names[i].replace('_vv', '')\n",
    "    flood_label_path = os.path.join(train_dir, region_name_dates1[i], 'tiles', 'flood_label', flood_image_name)\n",
    "    flood_label_paths.append(flood_label_path)\n",
    "\n",
    "    # get water body mask path\n",
    "    water_body_label_name = background_image_names[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(train_dir, region_name_dates1[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths.append(water_body_label_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:03:38.267703Z",
     "iopub.status.busy": "2025-03-22T13:03:38.267378Z",
     "iopub.status.idle": "2025-03-22T13:03:38.274521Z",
     "shell.execute_reply": "2025-03-22T13:03:38.273867Z",
     "shell.execute_reply.started": "2025-03-22T13:03:38.267647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Shuffle the index and then split in train and validation\n",
    "n=len(vv_image_paths) #number of images in the dataset\n",
    "arr = np.arange(n) #array 0...n-1\n",
    "np.random.shuffle(arr) # shuffle it\n",
    "train_idx=arr[0:int(np.round(0.80*n))] #80% train\n",
    "valid_idx=arr[int(np.round(0.80*n)):] #20% validation\n",
    "print(\"Number of tiles in training set:\",train_idx.size)\n",
    "print(\"Number of tiles in validation set:\",valid_idx.size)\n",
    "print(\"Number of tiles in the training and validation set:\",train_idx.size+valid_idx.size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T12:55:09.151492Z",
     "iopub.status.busy": "2025-03-22T12:55:09.151172Z",
     "iopub.status.idle": "2025-03-22T12:55:09.307149Z",
     "shell.execute_reply": "2025-03-22T12:55:09.306184Z",
     "shell.execute_reply.started": "2025-03-22T12:55:09.151466Z"
    },
    "id": "gZyCCloXZ51l",
    "outputId": "ae54dad0-ad9e-4ea7-d7ad-0f5b95934898",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vv_image_paths_train = list(np.array(vv_image_paths)[train_idx])\n",
    "vh_image_paths_train = list(np.array(vh_image_paths)[train_idx])\n",
    "flood_label_paths_train = list(np.array(flood_label_paths)[train_idx])\n",
    "water_body_label_paths_train = list(np.array(water_body_label_paths)[train_idx])\n",
    "\n",
    "train_paths = {'vv_image_path': vv_image_paths_train,\n",
    "        'vh_image_path': vh_image_paths_train,\n",
    "        'flood_label_path': flood_label_paths_train,\n",
    "        'water_body_label_path': water_body_label_paths_train,\n",
    "}\n",
    "\n",
    "train_df = pd.DataFrame(train_paths)\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T12:55:11.307099Z",
     "iopub.status.busy": "2025-03-22T12:55:11.306795Z",
     "iopub.status.idle": "2025-03-22T12:55:11.365783Z",
     "shell.execute_reply": "2025-03-22T12:55:11.365048Z",
     "shell.execute_reply.started": "2025-03-22T12:55:11.307077Z"
    },
    "id": "-NHxJjumZ51m",
    "outputId": "806d8270-8fe9-4805-ef23-3bf95030e2f9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vv_image_paths_valid = list(np.array(vv_image_paths)[valid_idx])\n",
    "vh_image_paths_valid = list(np.array(vh_image_paths)[valid_idx])\n",
    "flood_label_paths_valid = list(np.array(flood_label_paths)[valid_idx])\n",
    "water_body_label_paths_valid = list(np.array(water_body_label_paths)[valid_idx])\n",
    "\n",
    "valid_paths = {'vv_image_path': vv_image_paths_valid,\n",
    "        'vh_image_path': vh_image_paths_valid,\n",
    "        'flood_label_path': flood_label_paths_valid,\n",
    "        'water_body_label_path': water_body_label_paths_valid,\n",
    "}\n",
    "\n",
    "\n",
    "valid_df = pd.DataFrame(valid_paths)\n",
    "\n",
    "print(valid_df.shape)\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IVYdPhmZ51m"
   },
   "source": [
    "## # Step 2b: Create training undersampled dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:03:03.333884Z",
     "iopub.status.busy": "2025-03-22T13:03:03.333494Z",
     "iopub.status.idle": "2025-03-22T13:03:09.182133Z",
     "shell.execute_reply": "2025-03-22T13:03:09.181381Z",
     "shell.execute_reply.started": "2025-03-22T13:03:03.333858Z"
    },
    "id": "XQusiCs3Z51m",
    "outputId": "282220bc-7d7b-422e-91cd-b20bc44272bf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "background_image_paths_train = [path for path in background_image_paths if path in vv_image_paths_train]\n",
    "background_num_train = len(background_image_paths_train)\n",
    "print('Number of background tiles included in training:',background_num_train)\n",
    "\n",
    "water_image_paths_train = [path for path in water_image_paths if path in vv_image_paths_train]\n",
    "water_image_names_train = [get_filename(pth) for pth in water_image_paths_train]\n",
    "region_name_dates2 = ['_'.join(n.split('_')[:2]) for n in water_image_names_train]\n",
    "water_num_train = len(water_image_paths_train)\n",
    "print('Number of water tiles included in training:',water_num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T12:56:00.098331Z",
     "iopub.status.busy": "2025-03-22T12:56:00.098060Z",
     "iopub.status.idle": "2025-03-22T12:56:00.183032Z",
     "shell.execute_reply": "2025-03-22T12:56:00.182423Z",
     "shell.execute_reply.started": "2025-03-22T12:56:00.098299Z"
    },
    "id": "C5kkSq70Z51m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_samples = int(water_num_train * 0.15) #include 15% of water tiles\n",
    "arr = np.arange(int(water_num_train * 0.15))  # array 0...n-1\n",
    "np.random.shuffle(arr)  # shuffle it\n",
    "background_image_paths_train_undersampled = list(np.array(background_image_paths_train)[arr[0:num_samples]])\n",
    "background_image_names_train_undersampled = [get_filename(pth) for pth in background_image_paths_train_undersampled]\n",
    "print('Number of background tiles included in training after undersampling:',len(background_image_names_train_undersampled))\n",
    "region_name_dates3 = ['_'.join(n.split('_')[:2]) for n in background_image_names_train_undersampled]\n",
    "\n",
    "vh_image_paths_train_undersampled, flood_label_paths_train_undersampled, water_body_label_paths_train_undersampled = [], [], []\n",
    "for i in range(len(water_image_names_train)):\n",
    "    # get vh image path\n",
    "    vh_image_name = water_image_names_train[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(train_dir, region_name_dates2[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths_train_undersampled.append(vh_image_path)\n",
    "\n",
    "    # get flood mask path\n",
    "    flood_image_name = water_image_names_train[i].replace('_vv', '')\n",
    "    flood_label_path = os.path.join(train_dir, region_name_dates2[i], 'tiles', 'flood_label', flood_image_name)\n",
    "    flood_label_paths_train_undersampled.append(flood_label_path)\n",
    "\n",
    "    # get water body mask path\n",
    "    water_body_label_name = water_image_names_train[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(train_dir, region_name_dates2[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths_train_undersampled.append(water_body_label_path)\n",
    "\n",
    "vv_image_paths_train_undersampled = water_image_paths_train\n",
    "print('Number of water body label included in training after undersampling:',len(water_body_label_paths_train_undersampled))\n",
    "for i in range(len(background_image_names_train_undersampled)):\n",
    "    vv_image_paths_train_undersampled.append(background_image_paths_train_undersampled[i])\n",
    "    \n",
    "    # get vh image path\n",
    "    vh_image_name = background_image_names_train_undersampled[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(train_dir, region_name_dates3[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths_train_undersampled.append(vh_image_path)\n",
    "\n",
    "    # get flood mask path\n",
    "    flood_image_name = background_image_names_train_undersampled[i].replace('_vv', '')\n",
    "    flood_label_path = os.path.join(train_dir, region_name_dates3[i], 'tiles', 'flood_label', flood_image_name)\n",
    "    flood_label_paths_train_undersampled.append(flood_label_path)\n",
    "\n",
    "    # get water body mask path\n",
    "    water_body_label_name = background_image_names_train_undersampled[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(train_dir, region_name_dates3[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths_train_undersampled.append(water_body_label_path)\n",
    "assert len(vv_image_paths_train_undersampled)==len(vh_image_paths_train_undersampled)==len(flood_label_paths_train_undersampled)==len(water_body_label_paths_train_undersampled)\n",
    "print('Number of overall images  included in training after undersampling:',len(water_body_label_paths_train_undersampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Based on the consideration done in Lab1 and the above calculation, explain the original dataset is in term of class imbalance and how this changed in the undersample dataset.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER HERE:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:06:19.977485Z",
     "iopub.status.busy": "2025-03-22T13:06:19.977172Z",
     "iopub.status.idle": "2025-03-22T13:06:19.993274Z",
     "shell.execute_reply": "2025-03-22T13:06:19.992514Z",
     "shell.execute_reply.started": "2025-03-22T13:06:19.977464Z"
    },
    "id": "SlYQhz19Z51m",
    "outputId": "5e2d24fa-4186-4408-90e3-72a4c7ae9a43",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_paths_undersample = {'vv_image_path': vv_image_paths_train_undersampled,\n",
    "        'vh_image_path': vh_image_paths_train_undersampled,\n",
    "        'flood_label_path': flood_label_paths_train_undersampled,\n",
    "        'water_body_label_path': water_body_label_paths_train_undersampled\n",
    "}\n",
    "train_df_undersample = pd.DataFrame(train_paths_undersample)\n",
    "\n",
    "print(train_df_undersample.shape)\n",
    "train_df_undersample.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKsPrdqVQ-U1"
   },
   "source": [
    "# Step 3: Visualize images\n",
    "\n",
    "This section is meant to be used to experiment the data. Feel free to change things and to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:06:23.282270Z",
     "iopub.status.busy": "2025-03-22T13:06:23.281992Z",
     "iopub.status.idle": "2025-03-22T13:06:23.295210Z",
     "shell.execute_reply": "2025-03-22T13:06:23.294513Z",
     "shell.execute_reply.started": "2025-03-22T13:06:23.282250Z"
    },
    "id": "eYKur3pfZ51m",
    "outputId": "90bd7fce-9e54-48c9-b38e-b09856f8a3f2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:06:24.831521Z",
     "iopub.status.busy": "2025-03-22T13:06:24.831215Z",
     "iopub.status.idle": "2025-03-22T13:06:24.876627Z",
     "shell.execute_reply": "2025-03-22T13:06:24.875744Z",
     "shell.execute_reply.started": "2025-03-22T13:06:24.831495Z"
    },
    "id": "qW1LQOAFZ51m",
    "outputId": "142e3d5a-239f-4a55-866f-edab617d502d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cv2.imread(train_df_undersample.iloc[1200]['vv_image_path'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:06:25.803509Z",
     "iopub.status.busy": "2025-03-22T13:06:25.803236Z",
     "iopub.status.idle": "2025-03-22T13:06:25.808691Z",
     "shell.execute_reply": "2025-03-22T13:06:25.807845Z",
     "shell.execute_reply.started": "2025-03-22T13:06:25.803489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_undersample.iloc[3600]['vv_image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:06:26.326556Z",
     "iopub.status.busy": "2025-03-22T13:06:26.326282Z",
     "iopub.status.idle": "2025-03-22T13:06:27.381465Z",
     "shell.execute_reply": "2025-03-22T13:06:27.379544Z",
     "shell.execute_reply.started": "2025-03-22T13:06:26.326532Z"
    },
    "id": "A7n_4toNZ51n",
    "outputId": "2b9163df-a836-471b-cf19-cda0d24c4e32",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize(train_df_undersample.iloc[3600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:06:28.232292Z",
     "iopub.status.busy": "2025-03-22T13:06:28.232009Z",
     "iopub.status.idle": "2025-03-22T13:06:29.135348Z",
     "shell.execute_reply": "2025-03-22T13:06:29.134497Z",
     "shell.execute_reply.started": "2025-03-22T13:06:28.232270Z"
    },
    "id": "wV30Ip_2Qyqz",
    "outputId": "11cef363-ed6e-4fea-fd01-107bfeb9a0ad",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize(train_df.iloc[3677])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW5yZ_I0RFK6"
   },
   "source": [
    "# Step 4: Setup the dataset for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caUo_wp8dfrU"
   },
   "source": [
    "Since the Phase 1 (Development phase) of the ETCI 2021 Competition on Flood Detection provided with training data (which includes reference data) and a validation data (without reference data until phase 1 concludes),we will split our training dataset (that contains flood masks) into a smaller training and development set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HzZPldyduaO"
   },
   "source": [
    "### Create a PyTorch dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcu24qx0dutc"
   },
   "source": [
    "We will be using the PyTorch deep learning library to format this dataset and create our machine learning model. Therefore we will need to create a custom Dataset class and pass it into a DataLoader object (see the [PyTorch Dataset Tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)  for more detail on the topic). To compute image transformations we will use the [Albumentations](https://github.com/albumentations-team/albumentations) package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:06:32.520001Z",
     "iopub.status.busy": "2025-03-22T13:06:32.519692Z",
     "iopub.status.idle": "2025-03-22T13:06:32.527537Z",
     "shell.execute_reply": "2025-03-22T13:06:32.526763Z",
     "shell.execute_reply.started": "2025-03-22T13:06:32.519978Z"
    },
    "id": "Gus4cgUzdx3o",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ETCIDataset(Dataset):\n",
    "    def __init__(self, dataframe, split, transform=None):\n",
    "        self.split = split\n",
    "        self.dataset = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = {}\n",
    "        \n",
    "        df_row = self.dataset.iloc[index]\n",
    "\n",
    "        # load vv and vh images\n",
    "        vv_image = cv2.imread(df_row['vv_image_path'], 0) / 255.0\n",
    "        vh_image = cv2.imread(df_row['vh_image_path'], 0) / 255.0\n",
    "        \n",
    "        # convert vv and vh images to rgb\n",
    "        rgb_image = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "        if self.split == 'test':\n",
    "            # no flood mask should be available\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')  #HWC->CHW\n",
    "        else:\n",
    "            # load ground truth flood mask\n",
    "            flood_mask = cv2.imread(df_row['flood_label_path'], 0) / 255.0\n",
    "\n",
    "            # compute transformations\n",
    "            \n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=rgb_image, mask=flood_mask)\n",
    "                rgb_image = augmented['image']\n",
    "                flood_mask = augmented['mask']\n",
    "\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32') #HWC->CHW\n",
    "            example['mask'] = flood_mask.astype('int64')\n",
    "\n",
    "        return example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Check the [Albumentations](https://github.com/albumentations-team/albumentations) package and implement both Vertical and Horizontal flip with probability 0.5 and RandomResizedCrop of 256 on both dimentions. Then load the train and validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:43:22.985278Z",
     "iopub.status.busy": "2025-03-22T13:43:22.985002Z",
     "iopub.status.idle": "2025-03-22T13:43:22.993056Z",
     "shell.execute_reply": "2025-03-22T13:43:22.992315Z",
     "shell.execute_reply.started": "2025-03-22T13:43:22.985258Z"
    },
    "id": "ls9VrVu1d3Ba",
    "outputId": "bde87a1d-c20e-48a2-b56a-8a69b52a0796",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "### BEGINNING OF THE CODE\n",
    "# trasform= ...\n",
    "#train_dataset = ...\n",
    "#valid_dataset = ...\n",
    "####END OF THE CODE\n",
    "print('Trainining set size:',len(train_dataset))\n",
    "print('Validation set size:',len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:43:23.350316Z",
     "iopub.status.busy": "2025-03-22T13:43:23.350074Z",
     "iopub.status.idle": "2025-03-22T13:43:23.354808Z",
     "shell.execute_reply": "2025-03-22T13:43:23.353979Z",
     "shell.execute_reply.started": "2025-03-22T13:43:23.350297Z"
    },
    "id": "JvFR5E2deuKI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:43:24.011584Z",
     "iopub.status.busy": "2025-03-22T13:43:24.011287Z",
     "iopub.status.idle": "2025-03-22T13:43:24.016367Z",
     "shell.execute_reply": "2025-03-22T13:43:24.015695Z",
     "shell.execute_reply.started": "2025-03-22T13:43:24.011560Z"
    },
    "id": "ToOeMH-rZ51n",
    "outputId": "2d707ca4-8f89-480e-c926-941be969a9ca",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_undersampled_dataset = ETCIDataset(train_df_undersample, split='train', transform=transform)\n",
    "train_undersampled_loader = DataLoader(train_undersampled_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "print('Undersampled Trainining set size:',len(train_undersampled_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxKtsgcDRFf_"
   },
   "source": [
    "# Step 5: Deep learning model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE7RhfwFe2Rt"
   },
   "source": [
    "### Select hardware to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:43:27.005913Z",
     "iopub.status.busy": "2025-03-22T13:43:27.005490Z",
     "iopub.status.idle": "2025-03-22T13:43:27.009422Z",
     "shell.execute_reply": "2025-03-22T13:43:27.008600Z",
     "shell.execute_reply.started": "2025-03-22T13:43:27.005886Z"
    },
    "id": "Uc2z3thWRG5Q",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Gkp1E5ne4yg"
   },
   "source": [
    "**3) Read carefully the documentation of the segmentation model from the [Segmentation Models](https://github.com/qubvel/segmentation_models.pytorch) package ([documentation here](https://smp.readthedocs.io/en/latest/)),  implement a UNet with resnet34 as encoder, without any pre-trained weights, and the appropriate number of in_channel and classes based on the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-22T13:43:27.733048Z",
     "iopub.status.busy": "2025-03-22T13:43:27.732724Z",
     "iopub.status.idle": "2025-03-22T13:43:27.737065Z",
     "shell.execute_reply": "2025-03-22T13:43:27.736238Z",
     "shell.execute_reply.started": "2025-03-22T13:43:27.733022Z"
    },
    "id": "Khe5IwgWRG-O",
    "outputId": "fc400e74-8829-4842-ba7c-5ede555d35a1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  ###CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:43:28.925562Z",
     "iopub.status.busy": "2025-03-22T13:43:28.925245Z",
     "iopub.status.idle": "2025-03-22T13:43:29.615743Z",
     "shell.execute_reply": "2025-03-22T13:43:29.614930Z",
     "shell.execute_reply.started": "2025-03-22T13:43:28.925535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_1 = create_model()\n",
    "model_1.to(device) # load model into GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7M0UMy-fmco"
   },
   "source": [
    "### Metric tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:43:32.794255Z",
     "iopub.status.busy": "2025-03-22T13:43:32.793967Z",
     "iopub.status.idle": "2025-03-22T13:43:33.168619Z",
     "shell.execute_reply": "2025-03-22T13:43:33.167728Z",
     "shell.execute_reply.started": "2025-03-22T13:43:32.794234Z"
    },
    "id": "lItS5ROIRHZp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class EvalTracker:\n",
    "    def __init__(self, n_classes=2, smooth=0.0001):\n",
    "        self.n_classes = n_classes\n",
    "        self.reset()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def reset(self):\n",
    "        self.cm = np.zeros((self.n_classes, self.n_classes))\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, pred, target):\n",
    "        # pred: [B, 2, H, W]\n",
    "        # target: [B, H, W]\n",
    "        self.count += pred.shape[0]\n",
    "\n",
    "        # reshape inputs\n",
    "        pred = pred.argmax(dim=1).flatten()  # [B*H*W]\n",
    "        target = target.flatten()  # [B*H*W]\n",
    "\n",
    "        # put into cpu memory\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        target = target.detach().cpu().numpy()\n",
    "\n",
    "        # compute confusion matrix values\n",
    "        self.cm += confusion_matrix(target, pred)\n",
    "\n",
    "    def get_mean(self):\n",
    "        tn, fp, fn, tp = self.cm.ravel()\n",
    "\n",
    "        # compute IoU\n",
    "        iou = tp / (tp + fp + fn + self.smooth)\n",
    "        prec = tp / (tp + fp + self.smooth)\n",
    "        rec = tp / (tp + fn + self.smooth)\n",
    "        f1 = 2.0*prec*rec/(prec+rec)\n",
    "\n",
    "        return iou, prec, rec, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEIxsS7cRHGQ"
   },
   "source": [
    "# Step 6: Train model on the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0TolVLxfUQp"
   },
   "source": [
    "### Model config, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:43:35.538280Z",
     "iopub.status.busy": "2025-03-22T13:43:35.537776Z",
     "iopub.status.idle": "2025-03-22T13:43:35.543600Z",
     "shell.execute_reply": "2025-03-22T13:43:35.542725Z",
     "shell.execute_reply.started": "2025-03-22T13:43:35.538257Z"
    },
    "id": "lXGgG0lXfWNa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# set the number of times you want the model to see all of the training data\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=learning_rate)\n",
    "criteria_no_weights = nn.CrossEntropyLoss(weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAVBREKVfsC_"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3e1e0078ced04e258f5ec2a71d0ada5e",
      "2a6fcb9b01d94083b0a009ec3989e4d2",
      "51359be7b8e84f87ab8e55be40b8cfaa",
      "ec477cfd5be64d2caffa8f26ca01225c",
      "ef0620d9a5414295acbef70de6bc6f95",
      "5a774f56f91e44dd8655c5f31510938d",
      "3d885c493b9f455daa350ed13ad63cb4",
      "625387a7ff4c45f29ec1dc1dbad1e00a",
      "f3d896432e81468e9fa0b25c07290e4f",
      "726ca5126b6747ed8f017b589e568c0c",
      "d6fcca5df1644d41aa9ef7c1f85e4e44",
      "55a3285d3fba495880e8d01409ecc476",
      "4deb143236df4675be8d2ca2530f91aa",
      "e50e7ccd8be84ad6bade131baa65d33f",
      "5479e407bfff4a5b921f9c68b931e5a0",
      "f4c698a2ed3d4285b45b55ffda7f4c54",
      "11897b21381345499040735a970b514c",
      "7b64ddd78d614c528a3d807eb30bdbe6",
      "5ca91c5c1e864e4eb2c701593409ddfa",
      "f21b06a9ab644d3e834e0d0a91b009ec",
      "0a6985a5bbaf497db7fec4dbe0c12235",
      "185036b31f9c485a943f139e52400790",
      "22239c22f0d74d8ab2f1e9d26cac5e5a",
      "70dec6b4051d4115bb3ea2872d3715cb",
      "f232fc19003b4d209ce0d82757bdd475",
      "691111e7300e46788f6c7773b315867b",
      "e318fa8cb12d488389e7513a1d9220bb",
      "fc1d3379629d42debd9fa75be80aedbb",
      "42b6de65ebab4a76a54f6b664c90c322",
      "4aff01b384bb44b2b6bee9f971146dee",
      "f9df3d51fcb340b7a11fe792ef331a12",
      "b5861967ef144a9ebb814a727c4e9aab",
      "68793b9f9968463783536d7c3bd4d6d3",
      "4611a877d4614450ab387bf8fbed1e88",
      "4ba0f9eaa00842b8b885bc1114274fde",
      "bd1e892360b64560ba97fb9a1183d7b2",
      "b064dd455b58408db29fd13287e9a99a",
      "61d7c2bd5bf04e7b984e62b82d4669c4",
      "df51ea16e97648888b6493e9281cfb42",
      "ebcf75372dcd4090b1b1e9613a6c2cb2",
      "1642e6ad83414ac099c340bd70964eb0",
      "348d7c18c9a9474c997d5819f4043d33",
      "796bdd1c4878416fbf5ab7913467a608",
      "77bc8a4ae37c4068a03af8359eecf291",
      "d6266fc64a5d4785821141246e22b5f3",
      "46df6c35c482484398a109a85c7cf7a4",
      "a76e78c06ddd4221bda14bcac4094cd3",
      "8178219667c748ecbe0a6a13429be4f2",
      "ce209c8f23fc41898688bf5cdbdc5006",
      "d67205b7e1764c0eb921b84e27b67938",
      "c30f75ff0d70488aaaa9d4b82faafffa",
      "0be004947d7c41c5bd327643510a8a08",
      "eda26a17c0e54e3784e29319584aebf2",
      "4a20023a0c424888a87f3cb835ffc722",
      "02460f160c7e47eea1566f2ed9c0c1d7",
      "9c4e1618fe6e428eb391ac9c8acba54d",
      "8adfd49ca49a43efae3d0a24f01e6aa9",
      "128e71cea09c4bb8aaa36d4e244cadf9",
      "dfa071a8d1a24c058ea3458fd264dea1",
      "e8a0d735de9f454ab420199e2ad4915c",
      "d765e8a344734cbcb398f08290387833",
      "beb42a6bc5ce442bbba7d091d6edff12",
      "5a0c8c0dabec4b8cb2dac6b0630e212c",
      "7ab3dfc6e0574ad1b67fdcb791993a74",
      "e2ec6cd5f5584e2f8a8fa30afbdd3c70",
      "9f9733b736bd400c97a241e5820b78ea",
      "9a8ab992b5ab4e77bcf4f71878f21002",
      "a09554dbf1b94244bf9905865c3dc540",
      "38e01b8a27a84d01acb07984639f7b11",
      "0182f3ed00894753b8895b5178d91c4c",
      "39f6f32de0bb4dd8a79a59a6a80ecc58",
      "50e1d83c80fe47e19a68d35510c20101",
      "380193d5c40a42f2ab6b93d294a0d253",
      "ca47b1d14a5a4d479dabcd331a432ca2",
      "9a493c865e78457fb4a5ce83f77c87fd",
      "00a143eec0b443b6b06865355d07fbdc",
      "e8ce929bf9564f6185db5c0fa883cf43",
      "cc5eeb657b154d278ad3ae1cbdcedcfb",
      "eec6d4f8f39e4c26b934b487f9e5f83c",
      "652c1524c9204a3ca359cbe99dcb86ae",
      "83939c000bf044158043e8b3e2bb5740",
      "6cc71ce185e3475e8f5f6068a6b358f3",
      "385860c68f9a4389b0488e055ec92c2e",
      "263fde3c7eca4b11a9e5935eafef16c4",
      "7c15a341942848f3b491fd7e809e4b2a",
      "7da185f461634731a30c2766a720ea2c",
      "fd705fca61c24bbba5428df6aa60d3cb",
      "deac97e4fae44d309e05868ff520325f",
      "dfda9d41ff824e8aa8834b821342d939",
      "9834209e55b744dea67202a3e426e538",
      "4ee7318d994e47f5b2b0f23524b8cc41",
      "853a56aee125425597a8494441ee7601",
      "55d3d27dd61a4c9b90987ef193fdb8dc",
      "c37f721eb72143d3930193cee5f3e6e7",
      "0924d42b12ef4f1b989d41e9ce43f2be",
      "fdf51a682b974e4aac1cae3f6e541660",
      "fc97560541ba4f98b9cc3afef9f45962",
      "7c8ac804889549c7b52b374e41e159cf",
      "23a3f74eba28436f8c6a9bcbc1feb9f3",
      "6ad752a302de4ab481479712282ab88b",
      "20128cdb83e04412b6876d4f102b8b62",
      "9235c3faa06a4831adb4251c9cfeee5a",
      "399e4cd5377847b6a2397125108ac0fe",
      "3c4bc140916d42f58254bf7eb0cc1e10",
      "e7d0ca09b044483a9541609342537365",
      "d763e51ddeca49cf9c7ef38a3ad13510",
      "388547cf638c4aec9955a7b961658cf6",
      "3ff3d4e7790b42d3b71b74e9482136e2",
      "31fa03edaf514acfada4441d7ebefa38",
      "c253da26f3c543a39934bee90f043d02",
      "74a6bbfe3c5a46909a90e8e83c2b9a3d",
      "b90722916fc64706a72fb8dc9f153bc3",
      "8e21e576e98946a6bda5c0fd91feccf6",
      "f4a97f20cc3048c4976dfdf861d9ef83",
      "2f4c59bfeacc4bc282e30a2ea8c1cf07",
      "33cdb4149107485f9a49612db69494c7",
      "b574bfc9f95b41f487561b4bf2be1d08",
      "e724a3a0b7534dbf8f7fd71c0a4ef509",
      "b7a19a4b35f54d1ab74916af477c7b0e",
      "cb0d3d84a9204645ae7786029cb1ccbb",
      "39123395e37343d99258fdcfeaeebef1",
      "4749797b50184d8e9324e3f1f27f9db6",
      "765e80b436f847c897a8769bad279f60",
      "8ee67c14925947bca5b632df4bea759b",
      "c11fdeff535345bb9487ec0fc19bfd0a",
      "e4faaff263c4415aa29e3ac453f0b602",
      "773a64377df0469d92e76a6a3ac9bb86",
      "d34033b21bdf42ca84603040fbc83702",
      "d0e2c5d8500d48aa98143286c4d32030",
      "f135f38d2f1943178c9633f54614b946",
      "28e1499ba5224998bf8b841b4cd762a3",
      "8e2c0c6ae2084ba6a748b1db5cd686b4",
      "4db1277b18c64ceeb4eb0aa544ec6e9f",
      "25849803b46e404290693f28e292c712",
      "dc110ddf6bdc4735b31819d95109268d",
      "66a1b93b76ce40e892e3212553d05391",
      "e1dc06cd57c740a0807c884667b3396d",
      "94bb4ad33f1044f0b2aad4682bc5ce44",
      "4eb67a33c08f42cfb9928fc8fbef1e07",
      "ce280e030d7046118aa670a310c0af27",
      "4ae79db1fa6a4a039af0d9351638a755",
      "2aaa35e1ac114d11843852267b471081",
      "145e3cdf7c23417895e8438043046649",
      "5dce2ce1ae5849a8bb3caa24f1d5553b",
      "b7f44e49610a46658a0caff13ae45c22",
      "f757447abb96408fa3345be5f7bfde63",
      "0677876246eb4a8fb63f5114edb9ca4c",
      "7e18f508feb6463f90349c1a3f3d67a7",
      "e7d24a83cb184efea3e5c8af650b4442",
      "4211ae3893854d43a537807065ead01d",
      "cf33365abdd3447583f1730aa1d706a2",
      "75620c4906674553817ee2d431c81ee0",
      "fccc3f9b9a5e44b08e016cecd7034f2d",
      "53580f43b7ce47c4832bb2ffcb90ddea",
      "6c6422da2b754ffba93c6b6bbc35d1cf",
      "66bd2c46fb3f46ae86b753d138dbe024",
      "388e109cd04141e899b1cf3516922136",
      "73985b3486ec445dab23ef78fb49872c",
      "5b733eb5b6ef47eab159b67cac2bdb05",
      "dc712b83d5fc43218b6cf810cb58fd5f",
      "5545570e89d045f5b3671da311e184b5",
      "23b1b81699f04c0c861e2e31e009f82a",
      "538f0df88ec3445b986135f40a54ef2c",
      "a9e8c9c262874e8b93115f6d38271612",
      "f17f6697b5914f26a18b42f1058128a1",
      "6896fea1a7dd42b68ee0b2ce298c7b51",
      "9a6dcd6d822f4abd88ee728e96a7b01c",
      "decda69e62e942eab6ff9e7f05cea8e8",
      "11b95e3440414b1a910a5a91da6b67c1",
      "c22f964622a646a49c86ba4dbc953927",
      "445c1e4bd94549b5bf939ad4bcf07159",
      "db0d7447922e4abe882e67d978a91ff2",
      "22b54396fc69424fb0b0a158759dc541",
      "377a7a7cf74d4a3d9bb90e7a3b2cb5f0",
      "48fdc552b6b240b29fbed9c0f15eb5b9",
      "7bbbbdd8d2d14c41991fc66610fba34f",
      "ea25d4038cb74761bb433beffbb33737",
      "53fa76ce75f3450185f1682ea9425474",
      "a888aa3319704a028068042ae5aadd8b",
      "7ecabf140b7342bdb97b6bdb50d1779d",
      "fe157f3da1ef4524bc38c23039fa6a24",
      "da80fe6a35c04b769d8c33e9e895a9a5",
      "9b1e0940222d4c3dab43903fad7242b1",
      "4ea6232577564a96a647fc2e9c47e74c",
      "ebf2f1fc9f59426fbe4f1e954d57048a",
      "54dcfe4d62284536bcf8092b1997db7f",
      "cc1059d40c5e4bca82dedec539798ccf",
      "b2c06d217fc94383a242908c4a5543df",
      "b669090be2314c3190300ce6c9973ae8",
      "b2f099b2e52a4cc1ae9d3c0fed54667a",
      "6e6adc7e8f8a4f9188c8455abeaa09eb",
      "57a62b31705442aa851426282f555804",
      "159d2c7086794369a1b76774a031b094",
      "608f6085f1144094b929137b66e77cc7",
      "2e24a8440f7e4d84b58fe2932e769dcf",
      "96927fd0a3d14511aa6b975c394dd738",
      "5f598acce28042e998357e103523b55f",
      "f6bd0930080d4b58a13fd4035b800238",
      "589a76ebc95f4d2ebb31b98dacd4bb0c",
      "dcf578cfefd44aadb6120ac7fd0f5493",
      "9a781d7f4a9d4530ab50deabd6796e58",
      "0b7a61ef7cf04716962dc12fb67629e1",
      "22926e6fa8a34d1a9e4370fd28ced4f7",
      "ac22aa3323cc460b8ccddb864780a401",
      "fe2e6787c6554367b698f2a637a392fd",
      "f0d273a0b39c4f3f90bd9dfbe3ab4b99",
      "6fcd19d20b9b4de19f26838963e7a034",
      "64fb0f1a7356445889bfb16a473b4248",
      "3e53a7a8f05049baa796d6904f76517d",
      "1bc6567aa7cf44bf83930e70f17e61c9",
      "d14e1e01ea294812bf5fcf7f428b9d7f",
      "378f0864031e4f0a9bf61cb827149454",
      "0ae4ad91573d49f88a6278d0636442e8",
      "7540e35f814e42e3bdf25e2024d95772",
      "71de1afb96d84acba5af16bcd02d1236",
      "55e6617e37f142d9b08817632f0bd811",
      "3baced70d75148d1a8e6cf922655373b",
      "aae2f173f8e041ecade993c389fdd88f",
      "a5904e870bf44d149ac5f927c234afde",
      "58456c41ea1346849992130431b93dd7",
      "44358a2ad69341c1b7a7405b314d0deb",
      "e6976a6e5db244e89d6ebedd3e0e9838",
      "92b58b8e44854c1d84ac93bb6632fe0a",
      "58b9cb70fe13440ba82a9ea032a09125",
      "88cca7c4b79244939e74d767a24b8f10",
      "f2504de886e24c189ec6db4817293087",
      "e13fe371a5fb45d88f1222cc9c23b2a0",
      "6e70a57422da4293816bf8cf31424eb8",
      "6fd717904e4e4c22a1f0706bcfdae007",
      "74347627a2f5424ea8665507c528ce89",
      "687be928ce2f497eb87380b7a3122be3",
      "8657807d226e4a19b0c1ff57d9724a7c",
      "29c02ccbb54c4abc80dde696ebf82a7d",
      "1ef4fc745c1643a3a0c7c9ac4940f740",
      "60920ed7775e4bb19265f4696532b89b",
      "2f8cd038b3d442db992582e80354ac47",
      "54e5a6f9ba914e6b9a53d428d0ce7337",
      "47143be2a92641f69035ce150de9dc7c",
      "1c73f488efd148a6b76e95f5b7d5f0f3",
      "93323bfb000a49e78da78f0b79b60efd",
      "1556d564d3224883a2c46b1520234807",
      "8750c89891ba436886f95493ed7726db",
      "4ec877aff16f4025804672a685728e68",
      "766c7a5110c0478f9bce51296e2bfc80",
      "25d20a8dcb7b4cca9256a1529a92af4e",
      "04a96c861d1344c7a52693b3a3490615",
      "86290e4c169c4d3c9f9bfdd454220850",
      "ba7255c08c2141459829c4f121ab2eee",
      "a7ee110ed94c41739153153e70f2c0cd",
      "23de9120dbf1449695da4d1c68269b0c",
      "078f68d956444bbb930359c3f37da20a",
      "8b3b0b49d846436e857e90539993ce2f",
      "d82d6294bd104716829b468beaf3d03a",
      "b41647062cdc4652a65cedac36f7389a",
      "d5cef3718689474ea7ec87a0b2d4560b",
      "f99e2e0cbc3c4c02a8da206a17a3db87",
      "47e250b1c31d4a2ca250cc76c4767e76",
      "d470e537cc494444821b4a4d68ca054e",
      "ffdb41b94c4f473aa7dc633da6f3b42f",
      "722e0e3c0f454886beb74c734f3e6d54",
      "a1efadb6c770485b964927c4d1cb7874",
      "cd707f59c4f44fc884eb3eb94ecf3e41",
      "55822459bd68433cbf588f7f0067ca97",
      "83dd33b0a4b64cc3aeb698ebb760436f",
      "ef081bd648044439b71c53201ce2b083",
      "9790d51539e3420c97ed24be4ed036ad",
      "baf146a9aa5e4a9d9c6c500302f9c4f3",
      "31aae3a5d47348b29ab35a42b5a4d2ed",
      "97f7d194bca34946919fcc773e6debff",
      "0775eedb718043b2a4639c0643a3195a",
      "7a05da3824d04b7a9120f6acb7fe0e46",
      "213ebfa67ae84864bcb8fdda964e480c",
      "7adc32b6b5c04e11b2cf40a43b785f84",
      "e2b5b47fabc542ef95811f3680c48153",
      "f5aaba3881464b3ea7e7fe3679c0131f",
      "8f5b010b73d4464185d8d231a42ebfc8",
      "4382c41f9be442d69d2041ddd695206c",
      "d0e4d0df6330407289b9097fa63bc329",
      "908028398b08424ba436d199fb429c11",
      "e77a26d9d73e4455ac6caa44ddcf7a53",
      "55bc47314f374038a1700589963281c6",
      "26c5cdafd0804caa88fc00afe0ca1660",
      "8c12fd13a162487ca2e43388c4df1158",
      "5213f2b3c55d4447b9cd0e38a915ec49",
      "a17a00a2833d45bea87e66e37bf836bc",
      "6efa14baed734f0483bbbbd0cfe706d5",
      "53842b48b5574050bde5cf3a2bc2875e",
      "dfc4dc91ff344af2addfd97369b5bbd2",
      "5dfddaed88d64d1f89f10b5acc0adc5c",
      "75f3ffa5df534f4e8b2e3120c593c299",
      "e469168da58641aea18dc28bc847b4a4",
      "fb5f0c7edf724527ad6b19bf4665a648",
      "9bbfda04186d4719a23a775fb0d237e3",
      "e9e8b179f73f442687d355826e3ca087",
      "5e0b337a71784dcea10f590833aab9df",
      "46fb427d104b43be97c2321bc3293304",
      "7ce369a8ebc544499b333ed503c919e0",
      "dcb4425c4c7048e897d823faeff22183",
      "f57d66d5e9b743f09e92a8e84cc4ddb6",
      "57f870e4269d4c55be426895fe978ef2",
      "2f8be2bb8cd942bbad6b464e4d48344f",
      "3be126117882488ab5b9906c22584e11",
      "77381f5c9a33403294524ad1b3e6a47e",
      "2be4647666c3426e93dd912188b05a1f",
      "cb43775930da480380a6b7824a5cdfd4",
      "08b3885794d44724931e87897d5878ad",
      "4d19fa4b52d34898b0b5a3e0f6ddba0d",
      "07ab62ebf0de48be918f8d55c0bc214e",
      "81563e9b66a24ef2afcd546cc2c2c965",
      "f818aa4613ef4e3ca64ad25b7550af8f",
      "1923be8051f54984afbfeef581cc54af",
      "c411914b37fc4ddabc7796d9ed547a1c",
      "f8c9fd015b624c209d1bd3f131d5903e",
      "36f7e0436af74bf7b546a0dd704c8bba",
      "0933a5ed03b347298b9f59add2f50762",
      "bf78199ef02f42c69a9a665b44feb075",
      "a47130d64f4b49c8ba09c310edb80017",
      "d701aa2d416541748a7b18585f9c2aa0",
      "7b111a98f9774ef483d30e388dc56167",
      "7af0853027294425996f500b70a67d1e",
      "4f0bfc49d74049099419f4d9e8d651eb",
      "586acb4ffc874ef5a0af7d7bbe1a01fd",
      "84db05ffccac48a0b31fd7a1c3fb6719",
      "a0b31f8f6907459aa719a654846a8df1",
      "d10131e3ea7c47cb808c1c6f6fd1de88",
      "85723ef902b74589a7539790b793e9a4",
      "4594ed6a69744ccab94cec9a782abe57",
      "ff7f6df5ad494e61ad94560d2cecaae9",
      "789a194b179b495ca10391c17382ea98",
      "c7fbacecbbd44d1d8c994e6106741a7e",
      "62b1adb751964ea4a16a3d48619ea1a2",
      "ddf58b6b83dd49c4b96ef3d48b60cd50",
      "7e65f7aba23a4adea58bd16686403dce",
      "d1e4885c0e904c8dac3791cb8c183fa5",
      "f9c22234f5844c82bf992bd1ceb1fe74",
      "9e309c5944a5470db4230d20516c81c8",
      "55ca1573f7434458a054cc4feffd38ec",
      "a3616c48fb9a42cd861c4d064bea52f3",
      "b73f1e032ee34c04847c565c0c53fbd0",
      "f2f9d675ea284090a83062e1f15188c8",
      "b89cf5c848ed4b8e8f7c86ff8831cbdf",
      "800a8dbc477b4fe189ddc7cc394adcae"
     ]
    },
    "execution": {
     "execution_failed": "2025-03-22T14:44:05.110Z",
     "iopub.execute_input": "2025-03-22T13:43:40.295619Z",
     "iopub.status.busy": "2025-03-22T13:43:40.295332Z"
    },
    "id": "ZF15sV2Qft_1",
    "outputId": "1c07c60a-b1e0-4ca4-b3c2-3c58eb5c492d",
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_loss_dict={}\n",
    "val_loss_dict={}\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: [{}/{}]'.format(epoch+1, epochs))\n",
    "\n",
    "    # train set\n",
    "    pbar = tqdm(train_loader)\n",
    "    train_loss = 0.0\n",
    "    model_1.train()\n",
    "    eval_logger = EvalTracker()\n",
    "    for batch in pbar:\n",
    "        # load image and mask into device memory\n",
    "        image = batch['image'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "\n",
    "        # pass images into model\n",
    "        pred = model_1(image)\n",
    "\n",
    "        # get loss\n",
    "        loss = criteria_no_weights(pred, mask)\n",
    "\n",
    "        # update the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "               \n",
    "        # compute and display progress\n",
    "        eval_logger.update(pred, mask)\n",
    "        mIoU, Prec, Rec, f1 = eval_logger.get_mean()\n",
    "        pbar.set_description('Loss: {0:1.4f} | mIoU {1:1.4f} | Prec {2:1.4f} | Rec {3:1.4f}  | F1 score {4:1.4f}'.format(loss.item(), mIoU, Prec, Rec, f1))\n",
    "        train_loss += loss.item() * image.size(0)\n",
    "    # calculate the average loss for both training and validation\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_loss_dict[epoch] = train_loss\n",
    "        \n",
    "    # valid set\n",
    "    pbar = tqdm(valid_loader)\n",
    "    model_1.eval()\n",
    "    eval_logger = EvalTracker()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            # load image and mask into device memory\n",
    "            image = batch['image'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            # pass images into model\n",
    "            pred = model_1(image)\n",
    "\n",
    "            # get loss\n",
    "            loss = criteria_no_weights(pred, mask)\n",
    "                       \n",
    "            # compute and display progress\n",
    "            eval_logger.update(pred, mask)\n",
    "            mIoU, Prec, Rec, f1 = eval_logger.get_mean()\n",
    "            pbar.set_description('Loss: {0:1.4f} | mIoU {1:1.4f} | Prec {2:1.4f} | Rec {3:1.4f}  | F1 score {4:1.4f}'.format(loss.item(), mIoU, Prec, Rec, f1))\n",
    "            val_loss += loss.item() * image.size(0)\n",
    "    val_loss /= len(valid_loader.dataset)\n",
    "    val_loss_dict[epoch] = val_loss\n",
    "    \n",
    "# Save the training loss values\n",
    "with open('./train_loss_1_BCE.pkl', 'wb') as file:\n",
    "    pickle.dump(train_loss_dict, file)\n",
    "     \n",
    "# Save the validation loss values\n",
    "with open('./val_loss_1_BCE.pkl', 'wb') as file:\n",
    "    pickle.dump(val_loss_dict, file)            \n",
    "# save model\n",
    "torch.save(model_1.state_dict(), 'model_1_BCE.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T16:43:13.422792Z",
     "iopub.status.busy": "2023-04-13T16:43:13.421727Z",
     "iopub.status.idle": "2023-04-13T16:43:13.675050Z",
     "shell.execute_reply": "2023-04-13T16:43:13.673874Z",
     "shell.execute_reply.started": "2023-04-13T16:43:13.422751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the training and validation loss dictionaries\n",
    "train_loss = load(open('/kaggle/working/train_loss_1_BCE.pkl', 'rb'))\n",
    "val_loss = load(open('/kaggle/working/val_loss_1_BCE.pkl', 'rb'))\n",
    " \n",
    "# Retrieve each dictionary's values\n",
    "train_values = train_loss.values()\n",
    "val_values = val_loss.values()\n",
    " \n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs_range = range(1, epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs_range, train_values, label='Training Loss')\n",
    "plt.plot(epochs_range, val_values, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, epochs+1, 2))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Train model on the undersampled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "judvNQ6SEJPu"
   },
   "source": [
    "### Model config, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T16:43:18.883109Z",
     "iopub.status.busy": "2023-04-13T16:43:18.882662Z",
     "iopub.status.idle": "2023-04-13T16:43:19.389976Z",
     "shell.execute_reply": "2023-04-13T16:43:19.388783Z",
     "shell.execute_reply.started": "2023-04-13T16:43:18.883069Z"
    },
    "id": "4BwtBoqSZ51p"
   },
   "outputs": [],
   "source": [
    "model_2 = create_model()\n",
    "model_2.to(device)\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=learning_rate)\n",
    "criteria_no_weights = nn.CrossEntropyLoss(weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Implement a training loop similar to the one above but for the undersampled dataset. Use model_2 to avoid any overwriting of the previous model. Save the model as 'model_2d_BCE.pt'***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6GcVCvxEdWi"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T16:43:21.494909Z",
     "iopub.status.busy": "2023-04-13T16:43:21.494463Z",
     "iopub.status.idle": "2023-04-13T16:43:21.500097Z",
     "shell.execute_reply": "2023-04-13T16:43:21.498565Z",
     "shell.execute_reply.started": "2023-04-13T16:43:21.494853Z"
    }
   },
   "outputs": [],
   "source": [
    "### CODE HERE###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T18:34:21.212132Z",
     "iopub.status.busy": "2023-04-13T18:34:21.211791Z",
     "iopub.status.idle": "2023-04-13T18:34:21.530166Z",
     "shell.execute_reply": "2023-04-13T18:34:21.528811Z",
     "shell.execute_reply.started": "2023-04-13T18:34:21.212096Z"
    },
    "id": "-nodJ60UZ51p"
   },
   "outputs": [],
   "source": [
    "train_path =r'train_df.csv'\n",
    "valid_path = r'valid_df.csv'\n",
    "train_under_path = r'train_df_undersample.csv'\n",
    "train_df.to_csv(train_path)\n",
    "valid_df.to_csv(valid_path)\n",
    "train_df_undersample.to_csv(train_under_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T18:34:21.532950Z",
     "iopub.status.busy": "2023-04-13T18:34:21.531816Z",
     "iopub.status.idle": "2023-04-13T18:34:21.812028Z",
     "shell.execute_reply": "2023-04-13T18:34:21.810834Z",
     "shell.execute_reply.started": "2023-04-13T18:34:21.532901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the training and validation loss dictionaries\n",
    "train_loss = load(open('/kaggle/working/train_loss_2d_BCE.pkl', 'rb'))\n",
    "val_loss = load(open('/kaggle/working/val_loss_2d_BCE.pkl', 'rb'))\n",
    " \n",
    "# Retrieve each dictionary's values\n",
    "train_values = train_loss.values()\n",
    "val_values = val_loss.values()\n",
    " \n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs_range = range(1, epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs_range, train_values, label='Training Loss')\n",
    "plt.plot(epochs_range, val_values, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, epochs+1, 2))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAa4S_gUZ51p"
   },
   "source": [
    "# Step 8: Train model on the undersampled dataset with a weighted loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6frF1lcvF2ip"
   },
   "source": [
    "### Defining the split for the weighted Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T18:34:21.816359Z",
     "iopub.status.busy": "2023-04-13T18:34:21.815204Z",
     "iopub.status.idle": "2023-04-13T18:34:39.087524Z",
     "shell.execute_reply": "2023-04-13T18:34:39.086090Z",
     "shell.execute_reply.started": "2023-04-13T18:34:21.816311Z"
    },
    "id": "ELNpZUvkZ51p"
   },
   "outputs": [],
   "source": [
    "#It take quite a long time to calcualte, the ratio is around 5% flooded pixels, 95% background\n",
    "n_size = len(flood_label_paths_train_undersampled)\n",
    "n_flooded = np.ndarray((n_size,),)\n",
    "\n",
    "for i in tqdm(range(n_size)):\n",
    "    flood_label=cv2.imread(flood_label_paths_train_undersampled[i], 0)\n",
    "    n_flooded[i] = np.sum(flood_label)/255\n",
    "\n",
    "n_flooded_ratio = np.divide(n_flooded,256*256)\n",
    "flooded_pixels = np.sum(n_flooded)\n",
    "background_pixels = 256*256*n_size-np.sum(n_flooded)\n",
    "print(\"Flooded Pixels:\", flooded_pixels)\n",
    "print(\"Background Pixels:\", background_pixels)\n",
    "print(\"Ratio:\", np.mean(n_flooded_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnEFdTnqF-jx"
   },
   "source": [
    "### Model config, optimizer and loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Define the \"Model config, optimizer and loss function\" section as previously done but for \"model_3\" which will be trained with a [Weighted Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Remember to store the weights as a torch tensor, to load it in the GPU, and be careful on the order of your weights.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T18:34:39.090497Z",
     "iopub.status.busy": "2023-04-13T18:34:39.089645Z",
     "iopub.status.idle": "2023-04-13T18:34:39.096600Z",
     "shell.execute_reply": "2023-04-13T18:34:39.095086Z",
     "shell.execute_reply.started": "2023-04-13T18:34:39.090440Z"
    }
   },
   "outputs": [],
   "source": [
    "###CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Why did you choose the weights you used for the CrossEntropyLoss?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAdUT4J0GBkp"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T18:34:39.589867Z",
     "iopub.status.busy": "2023-04-13T18:34:39.589461Z",
     "iopub.status.idle": "2023-04-13T20:27:27.181120Z",
     "shell.execute_reply": "2023-04-13T20:27:27.179744Z",
     "shell.execute_reply.started": "2023-04-13T18:34:39.589824Z"
    },
    "id": "GCrkSsAiZ51p"
   },
   "outputs": [],
   "source": [
    "train_loss_dict={}\n",
    "val_loss_dict={}\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: [{}/{}]'.format(epoch+1, epochs))\n",
    "\n",
    "    # train set\n",
    "    pbar = tqdm(train_undersampled_loader)\n",
    "    train_loss = 0.0\n",
    "    model_3.train()\n",
    "    eval_logger = EvalTracker()\n",
    "    for batch in pbar:\n",
    "        # load image and mask into device memory\n",
    "        image = batch['image'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "\n",
    "        # pass images into model\n",
    "        pred = model_3(image)\n",
    "\n",
    "        # get loss\n",
    "        loss = criteria_weights(pred, mask)\n",
    "\n",
    "        # update the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute and display progress\n",
    "        eval_logger.update(pred, mask)\n",
    "        mIoU, Prec, Rec, f1 = eval_logger.get_mean()\n",
    "        pbar.set_description('Loss: {0:1.4f} | mIoU {1:1.4f} | Prec {2:1.4f} | Rec {3:1.4f}  | F1 score {4:1.4f}'.format(loss.item(), mIoU, Prec, Rec, f1))\n",
    "        train_loss += loss.item() * image.size(0)\n",
    "    # calculate the average loss for both training and validation\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_loss_dict[epoch] = train_loss\n",
    "    # valid set\n",
    "    pbar = tqdm(valid_loader)\n",
    "    val_loss = 0.0\n",
    "    model_3.eval()\n",
    "    eval_logger = EvalTracker()\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            # load image and mask into device memory\n",
    "            image = batch['image'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            # pass images into model\n",
    "            pred = model_3(image)\n",
    "\n",
    "            # get loss\n",
    "            loss = criteria_weights(pred, mask)\n",
    "            \n",
    "            # compute and display progress\n",
    "            eval_logger.update(pred, mask)\n",
    "            mIoU, Prec, Rec, f1 = eval_logger.get_mean()\n",
    "            pbar.set_description('Loss: {0:1.4f} | mIoU {1:1.4f} | Prec {2:1.4f} | Rec {3:1.4f}  | F1 score {4:1.4f}'.format(loss.item(), mIoU, Prec, Rec, f1))\n",
    "            val_loss += loss.item() * image.size(0)\n",
    "    val_loss /= len(valid_loader.dataset)\n",
    "    val_loss_dict[epoch] = val_loss\n",
    "# Save the training loss values\n",
    "with open('./train_loss_2d_WBCE.pkl', 'wb') as file:\n",
    "    pickle.dump(train_loss_dict, file)\n",
    "     \n",
    "# Save the validation loss values\n",
    "with open('./val_loss_2d_WBCE.pkl', 'wb') as file:\n",
    "    pickle.dump(val_loss_dict, file)   \n",
    "# save model\n",
    "torch.save(model_3.state_dict(), 'model_2d_WBCE.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:27:27.184418Z",
     "iopub.status.busy": "2023-04-13T20:27:27.183321Z",
     "iopub.status.idle": "2023-04-13T20:27:27.455019Z",
     "shell.execute_reply": "2023-04-13T20:27:27.453849Z",
     "shell.execute_reply.started": "2023-04-13T20:27:27.184366Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from pickle import load\n",
    "# Load the training and validation loss dictionaries\n",
    "train_loss = load(open('/kaggle/working/train_loss_2d_WBCE.pkl', 'rb'))\n",
    "val_loss = load(open('/kaggle/working/val_loss_2d_WBCE.pkl', 'rb'))\n",
    " \n",
    "# Retrieve each dictionary's values\n",
    "train_values = train_loss.values()\n",
    "val_values = val_loss.values()\n",
    " \n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs_range = range(1, epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs_range, train_values, label='Training Loss')\n",
    "plt.plot(epochs_range, val_values, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, epochs+1, 2))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) How are the three models (model_1_BCE.pt, model_2d_BCE.pt, and model_2d_WBCE.pt) performning? Comment the performances of the models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9AIegpgGH46"
   },
   "source": [
    "# Step 9a (Optional): Train more models\n",
    "Feel free to train mode model changing the configuration, learning rate, optimizer, loss function, etc. This is fully optional and bonus points will be assigned to go beyond the max grade. Total freedom here to create #Step 9b, 9c, etc.. Rememebr that this is 100% optional and won't influence your grading, it is a space to experiment ideas. I suggest you finalize the notebook first given the limited computational resources and get back to this later. \n",
    "\n",
    "Please add in the text cell below the idea behind the experiment you are about to run. Why do you want to test that specific conifguration? What do you expect in terms of results and what did you get after training? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:27:27.457314Z",
     "iopub.status.busy": "2023-04-13T20:27:27.456605Z",
     "iopub.status.idle": "2023-04-13T20:27:27.462621Z",
     "shell.execute_reply": "2023-04-13T20:27:27.461364Z",
     "shell.execute_reply.started": "2023-04-13T20:27:27.457270Z"
    },
    "id": "qnFKRGUsHkHU"
   },
   "outputs": [],
   "source": [
    "### CREATE A TEXT CELL BELOW AS EXPLAINED ABOVE EXPLAINING YOUR EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the second model with transfer learning from Imagenet using imagenet stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the dataloader (if needed) and the model (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:27:27.468667Z",
     "iopub.status.busy": "2023-04-13T20:27:27.467624Z",
     "iopub.status.idle": "2023-04-13T20:27:27.474051Z",
     "shell.execute_reply": "2023-04-13T20:27:27.472783Z",
     "shell.execute_reply.started": "2023-04-13T20:27:27.468633Z"
    }
   },
   "outputs": [],
   "source": [
    "### CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ0y5IfVGOyQ"
   },
   "source": [
    "### Model config, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:27:27.476412Z",
     "iopub.status.busy": "2023-04-13T20:27:27.475653Z",
     "iopub.status.idle": "2023-04-13T20:27:27.486376Z",
     "shell.execute_reply": "2023-04-13T20:27:27.485045Z",
     "shell.execute_reply.started": "2023-04-13T20:27:27.476370Z"
    }
   },
   "outputs": [],
   "source": [
    "###CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z72uKyRLGO3P"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:27:27.488981Z",
     "iopub.status.busy": "2023-04-13T20:27:27.488278Z",
     "iopub.status.idle": "2023-04-13T20:27:27.499100Z",
     "shell.execute_reply": "2023-04-13T20:27:27.497686Z",
     "shell.execute_reply.started": "2023-04-13T20:27:27.488930Z"
    }
   },
   "outputs": [],
   "source": [
    "### CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:27:27.501272Z",
     "iopub.status.busy": "2023-04-13T20:27:27.500936Z",
     "iopub.status.idle": "2023-04-13T20:27:27.510540Z",
     "shell.execute_reply": "2023-04-13T20:27:27.509353Z",
     "shell.execute_reply.started": "2023-04-13T20:27:27.501241Z"
    }
   },
   "outputs": [],
   "source": [
    "### CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQvNRXKJZ51p"
   },
   "source": [
    "# Step 10: Test models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu1hc68TZ51p"
   },
   "source": [
    "### Create a test dataset\n",
    "Let's create Dataset and DataLoader objects for the validation set. This time we will not have labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:27:27.514943Z",
     "iopub.status.busy": "2023-04-13T20:27:27.514198Z",
     "iopub.status.idle": "2023-04-13T20:28:06.250187Z",
     "shell.execute_reply": "2023-04-13T20:28:06.248905Z",
     "shell.execute_reply.started": "2023-04-13T20:27:27.514776Z"
    },
    "id": "1c5vxUcVZ51p"
   },
   "outputs": [],
   "source": [
    "vv_image_paths = sorted(glob(test_dir+'/**/vv/*.png', recursive=True))\n",
    "vv_image_names = [get_filename(pth) for pth in vv_image_paths]\n",
    "region_name_dates = ['_'.join(n.split('_')[:2]) for n in vv_image_names]\n",
    "\n",
    "vh_image_paths, flood_label_paths, water_body_label_paths, region_names = [], [], [], []\n",
    "for i in range(len(vv_image_paths)):\n",
    "    # get vh image path\n",
    "    vh_image_name = vv_image_names[i].replace('vv', 'vh')\n",
    "    vh_image_path = os.path.join(test_dir, region_name_dates[i], 'tiles', 'vh', vh_image_name)\n",
    "    vh_image_paths.append(vh_image_path)\n",
    "\n",
    "    # get flood mask path ()\n",
    "    flood_label_paths.append(np.NaN)\n",
    "\n",
    "    # get water body mask path\n",
    "    water_body_label_name = vv_image_names[i].replace('_vv', '')\n",
    "    water_body_label_path = os.path.join(test_dir, region_name_dates[i], 'tiles', 'water_body_label', water_body_label_name)\n",
    "    water_body_label_paths.append(water_body_label_path)\n",
    "\n",
    "    # get region name\n",
    "    region_name = region_name_dates[i].split('_')[0]\n",
    "    region_names.append(region_name)\n",
    "\n",
    "test_paths = {'vv_image_path': vv_image_paths,\n",
    "        'vh_image_path': vh_image_paths,\n",
    "        'flood_label_path': flood_label_paths,\n",
    "        'water_body_label_path': water_body_label_paths,\n",
    "        'region': region_names\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(valid_paths)\n",
    "\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf9XjEslZ51p"
   },
   "source": [
    "### Run inference\n",
    "\n",
    "**8) Choose your best performing model from Steps 6-9 and run inference below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:28:06.252452Z",
     "iopub.status.busy": "2023-04-13T20:28:06.252027Z",
     "iopub.status.idle": "2023-04-13T20:28:49.653699Z",
     "shell.execute_reply": "2023-04-13T20:28:49.652270Z",
     "shell.execute_reply.started": "2023-04-13T20:28:06.252410Z"
    },
    "id": "yvC772uZZ51p"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model_test = create_model()\n",
    "### CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiULZAt1Z51q"
   },
   "source": [
    "### Visualize some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:28:49.656621Z",
     "iopub.status.busy": "2023-04-13T20:28:49.656126Z",
     "iopub.status.idle": "2023-04-13T20:28:50.558589Z",
     "shell.execute_reply": "2023-04-13T20:28:50.555956Z",
     "shell.execute_reply.started": "2023-04-13T20:28:49.656574Z"
    },
    "id": "ON7nuVKqZ51q"
   },
   "outputs": [],
   "source": [
    "index = 252\n",
    "visualize_result(valid_df.iloc[index], final_predictions[index], figsize=(17,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:28:50.568135Z",
     "iopub.status.busy": "2023-04-13T20:28:50.560523Z",
     "iopub.status.idle": "2023-04-13T20:28:51.408445Z",
     "shell.execute_reply": "2023-04-13T20:28:51.407135Z",
     "shell.execute_reply.started": "2023-04-13T20:28:50.568090Z"
    },
    "id": "drAlY2e-Z51q"
   },
   "outputs": [],
   "source": [
    "index = -100\n",
    "visualize_result(valid_df.iloc[index], final_predictions[index], figsize=(17,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T20:44:19.142005Z",
     "iopub.status.busy": "2023-04-13T20:44:19.141104Z",
     "iopub.status.idle": "2023-04-13T20:44:19.993959Z",
     "shell.execute_reply": "2023-04-13T20:44:19.992907Z",
     "shell.execute_reply.started": "2023-04-13T20:44:19.141945Z"
    },
    "id": "_TI0nWXLZ51q"
   },
   "outputs": [],
   "source": [
    "index = 1910\n",
    "visualize_result(valid_df.iloc[index], final_predictions[index], figsize=(17,10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5110784,
     "sourceId": 8571359,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3131474,
     "sourceId": 8576812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
